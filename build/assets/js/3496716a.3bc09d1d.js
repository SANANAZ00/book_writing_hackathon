"use strict";(globalThis.webpackChunkphysical_ai_robotics=globalThis.webpackChunkphysical_ai_robotics||[]).push([[616],{5890:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>t,metadata:()=>a,toc:()=>c});var o=i(4848),s=i(8453);const t={title:"Module 2 - ROS 2 (Robotic Nervous System)",sidebar_position:2,description:"Understanding ROS 2 architecture and its role in humanoid robotics",tags:["ros2","robotics","middleware","communication"]},r="Module 2: ROS 2 (Robotic Nervous System)",a={id:"module-2-ros2",title:"Module 2 - ROS 2 (Robotic Nervous System)",description:"Understanding ROS 2 architecture and its role in humanoid robotics",source:"@site/docs/module-2-ros2.mdx",sourceDirName:".",slug:"/module-2-ros2",permalink:"/book_writing_hackathon/docs/module-2-ros2",draft:!1,unlisted:!1,editUrl:"https://github.com/SANANAZ00/book_writing_hackathon/edit/main/docs/module-2-ros2.mdx",tags:[{label:"ros2",permalink:"/book_writing_hackathon/docs/tags/ros-2"},{label:"robotics",permalink:"/book_writing_hackathon/docs/tags/robotics"},{label:"middleware",permalink:"/book_writing_hackathon/docs/tags/middleware"},{label:"communication",permalink:"/book_writing_hackathon/docs/tags/communication"}],version:"current",sidebarPosition:2,frontMatter:{title:"Module 2 - ROS 2 (Robotic Nervous System)",sidebar_position:2,description:"Understanding ROS 2 architecture and its role in humanoid robotics",tags:["ros2","robotics","middleware","communication"]},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/book_writing_hackathon/docs/intro"},next:{title:"Module 3 - Digital Twin (Gazebo & Unity)",permalink:"/book_writing_hackathon/docs/module-3-digital-twin"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"1. Introduction to ROS 2",id:"1-introduction-to-ros-2",level:2},{value:"Why ROS 2 for Humanoid Robotics?",id:"why-ros-2-for-humanoid-robotics",level:3},{value:"2. Core Components of ROS 2",id:"2-core-components-of-ros-2",level:2},{value:"2.1 Nodes: The Processing Units",id:"21-nodes-the-processing-units",level:3},{value:"2.2 Topics: Continuous Information Streams",id:"22-topics-continuous-information-streams",level:3},{value:"2.3 Services: Request-Response Interactions",id:"23-services-request-response-interactions",level:3},{value:"2.4 Actions: Long-Running Operations with Feedback",id:"24-actions-long-running-operations-with-feedback",level:3},{value:"3. Python Agent Integration with rclpy",id:"3-python-agent-integration-with-rclpy",level:2},{value:"4. URDF Fundamentals for Humanoid Robots",id:"4-urdf-fundamentals-for-humanoid-robots",level:2},{value:"5. Practical Exercise: Creating Your First ROS 2 System",id:"5-practical-exercise-creating-your-first-ros-2-system",level:2},{value:"Exercise 5.1: Joint Position Publisher",id:"exercise-51-joint-position-publisher",level:3},{value:"Exercise 5.2: Balance Controller",id:"exercise-52-balance-controller",level:3},{value:"6. Summary",id:"6-summary",level:2},{value:"Assessment",id:"assessment",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"module-2-ros-2-robotic-nervous-system",children:"Module 2: ROS 2 (Robotic Nervous System)"}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"After completing this module, you will be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Explain the core concepts of ROS 2 architecture and its role in humanoid robotics"}),"\n",(0,o.jsx)(n.li,{children:"Implement basic communication patterns using nodes, topics, services, and actions"}),"\n",(0,o.jsx)(n.li,{children:"Integrate Python agents with robot controllers using rclpy"}),"\n",(0,o.jsx)(n.li,{children:"Understand URDF fundamentals specific to humanoid robots"}),"\n",(0,o.jsx)(n.li,{children:"Create and test basic ROS 2 communication systems"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Basic Python programming knowledge"}),"\n",(0,o.jsx)(n.li,{children:"Understanding of Linux command line"}),"\n",(0,o.jsx)(n.li,{children:"Completion of Module 1: Introduction"}),"\n",(0,o.jsx)(n.li,{children:"Familiarity with fundamental robotics concepts"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"1-introduction-to-ros-2",children:"1. Introduction to ROS 2"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 (Robot Operating System 2) serves as the essential communication backbone that enables complex humanoid robot behaviors. Unlike traditional software systems, ROS 2 provides a distributed computing framework specifically designed for robotics applications, where multiple processes must coordinate seamlessly to achieve complex behaviors."}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robots specifically, ROS 2 addresses the unique challenge of coordinating dozens of sensors and actuators while maintaining real-time performance. Each component\u2014vision, motor control, balance, speech recognition\u2014needs to communicate with every other component, creating a complex web of interactions that ROS 2 manages efficiently."}),"\n",(0,o.jsx)(n.h3,{id:"why-ros-2-for-humanoid-robotics",children:"Why ROS 2 for Humanoid Robotics?"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require an extraordinary level of coordination between multiple subsystems. From maintaining balance while walking to processing visual input for object recognition, each component must communicate seamlessly with others. ROS 2 provides the infrastructure that allows these diverse systems to function as a unified intelligent agent."}),"\n",(0,o.jsx)(n.p,{children:"The distributed architecture of ROS 2 is particularly well-suited to humanoid robotics, where different components may run on different processors or even different physical computers within the robot. This flexibility allows for optimal resource allocation while maintaining reliable communication between all system components."}),"\n",(0,o.jsx)(n.h2,{id:"2-core-components-of-ros-2",children:"2. Core Components of ROS 2"}),"\n",(0,o.jsx)(n.h3,{id:"21-nodes-the-processing-units",children:"2.1 Nodes: The Processing Units"}),"\n",(0,o.jsx)(n.p,{children:"Nodes are the fundamental building blocks of any ROS 2 system. Think of a node as a specialized brain region\u2014each handles a specific function while remaining connected to the broader network. In a humanoid robot, you might have nodes dedicated to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Motor control for individual joints and limb coordination"}),"\n",(0,o.jsx)(n.li,{children:"Visual processing for cameras and depth sensors"}),"\n",(0,o.jsx)(n.li,{children:"Audio processing for speech recognition and synthesis"}),"\n",(0,o.jsx)(n.li,{children:"Balance and stability algorithms for locomotion"}),"\n",(0,o.jsx)(n.li,{children:"High-level decision making and behavior selection"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Each node runs independently and communicates with others through ROS 2's messaging system, creating a distributed architecture that's both flexible and robust."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example: Simple ROS 2 Node Structure\nimport rclpy\nfrom rclpy.node import Node\n\nclass SimpleRobotNode(Node):\n    def __init__(self):\n        super().__init__('simple_robot_node')\n        self.get_logger().info('Simple Robot Node initialized')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SimpleRobotNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h3,{id:"22-topics-continuous-information-streams",children:"2.2 Topics: Continuous Information Streams"}),"\n",(0,o.jsx)(n.p,{children:"Topics operate on a publish-subscribe model where one node publishes data and multiple nodes can subscribe to receive it, creating efficient one-to-many communication patterns essential for humanoid robotics. This system is perfect for continuous data streams like sensor readings, camera feeds, or joint position updates."}),"\n",(0,o.jsx)(n.p,{children:'For example, a camera node continuously publishes image data on a "camera_feed" topic, while multiple perception nodes (face detection, object recognition, depth estimation) can simultaneously subscribe to this stream. Similarly, joint position sensors continuously publish their readings, allowing control algorithms to monitor the robot\'s posture in real-time and make necessary adjustments.'}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example: Publisher Node\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n\nclass MinimalPublisher(Node):\n    def __init__(self):\n        super().__init__('minimal_publisher')\n        self.publisher_ = self.create_publisher(String, 'topic', 10)\n        timer_period = 0.5  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n        self.i = 0\n\n    def timer_callback(self):\n        msg = String()\n        msg.data = f'Hello Robot: {self.i}'\n        self.publisher_.publish(msg)\n        self.get_logger().info(f'Publishing: \"{msg.data}\"')\n        self.i += 1\n\ndef main(args=None):\n    rclpy.init(args=args)\n    minimal_publisher = MinimalPublisher()\n    rclpy.spin(minimal_publisher)\n    minimal_publisher.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example: Subscriber Node\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n\nclass MinimalSubscriber(Node):\n    def __init__(self):\n        super().__init__('minimal_subscriber')\n        self.subscription = self.create_subscription(\n            String,\n            'topic',\n            self.listener_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n\n    def listener_callback(self, msg):\n        self.get_logger().info(f'I heard: \"{msg.data}\"')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    minimal_subscriber = MinimalSubscriber()\n    rclpy.spin(minimal_subscriber)\n    minimal_subscriber.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h3,{id:"23-services-request-response-interactions",children:"2.3 Services: Request-Response Interactions"}),"\n",(0,o.jsx)(n.p,{children:"Services provide synchronous communication for discrete operations that require immediate responses, following a client-server pattern where one node requests an action and waits for completion. This is ideal for operations that must complete before other actions can proceed."}),"\n",(0,o.jsx)(n.p,{children:"In humanoid robots, services typically handle:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Calibration routines that must complete before movement"}),"\n",(0,o.jsx)(n.li,{children:"Database queries for retrieving stored information"}),"\n",(0,o.jsx)(n.li,{children:"Emergency stop procedures that require immediate confirmation"}),"\n",(0,o.jsx)(n.li,{children:"Configuration changes that need validation"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example: Service Server\nimport rclpy\nfrom rclpy.node import Node\nfrom example_interfaces.srv import AddTwoInts\n\nclass MinimalService(Node):\n    def __init__(self):\n        super().__init__('minimal_service')\n        self.srv = self.create_service(AddTwoInts, 'add_two_ints', self.add_two_ints_callback)\n\n    def add_two_ints_callback(self, request, response):\n        response.sum = request.a + request.b\n        self.get_logger().info(f'Incoming request\\na: {request.a}, b: {request.b}\\nsum: {response.sum}')\n        return response\n\ndef main(args=None):\n    rclpy.init(args=args)\n    minimal_service = MinimalService()\n    rclpy.spin(minimal_service)\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h3,{id:"24-actions-long-running-operations-with-feedback",children:"2.4 Actions: Long-Running Operations with Feedback"}),"\n",(0,o.jsx)(n.p,{children:"Actions bridge the gap between topics and services, handling operations that take time to complete while providing ongoing feedback. They're perfect for complex behaviors like walking, grasping, or navigation where progress must be monitored and potentially interrupted."}),"\n",(0,o.jsx)(n.p,{children:"An action system includes three components: a goal (what to do), feedback (progress updates), and result (final outcome). For a humanoid robot walking to a location, the action would accept the destination goal, continuously provide feedback on walking progress, and return success or failure upon completion."}),"\n",(0,o.jsx)(n.h2,{id:"3-python-agent-integration-with-rclpy",children:"3. Python Agent Integration with rclpy"}),"\n",(0,o.jsx)(n.p,{children:"rclpy serves as the Python interface to ROS 2, enabling developers to create ROS 2 nodes using familiar Python syntax. This integration is particularly valuable for humanoid robotics because Python excels at rapid prototyping, machine learning integration, and algorithm development\u2014critical aspects of physical AI systems."}),"\n",(0,o.jsx)(n.p,{children:"Through rclpy, Python-based AI agents can seamlessly integrate with the broader ROS 2 ecosystem. A vision-language-action system implemented in Python can subscribe to camera topics, process images using neural networks, and publish commands to motor control nodes\u2014all while leveraging ROS 2's robust communication infrastructure."}),"\n",(0,o.jsx)(n.p,{children:"The Python ecosystem's rich libraries for machine learning, computer vision, and natural language processing make rclpy an ideal choice for implementing the cognitive components of humanoid robots. Whether it's using TensorFlow for perception tasks or integrating with large language models for natural interaction, rclpy provides the bridge between advanced AI techniques and robotic hardware."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example: AI Agent Integration with rclpy\nimport rclpy\nfrom rclpy.node import Node\nimport numpy as np\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nimport cv2\nfrom cv_bridge import CvBridge\n\nclass AIAgentNode(Node):\n    def __init__(self):\n        super().__init__('ai_agent_node')\n\n        # Initialize computer vision bridge\n        self.bridge = CvBridge()\n\n        # Subscribe to camera feed\n        self.image_subscription = self.create_subscription(\n            Image,\n            'camera/image_raw',\n            self.image_callback,\n            10\n        )\n\n        # Publisher for AI decisions\n        self.decision_publisher = self.create_publisher(String, 'ai_decision', 10)\n\n        self.get_logger().info('AI Agent Node initialized')\n\n    def image_callback(self, msg):\n        # Convert ROS image message to OpenCV format\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n\n        # Process image with AI algorithm (simplified example)\n        decision = self.process_image(cv_image)\n\n        # Publish AI decision\n        decision_msg = String()\n        decision_msg.data = decision\n        self.decision_publisher.publish(decision_msg)\n        self.get_logger().info(f'AI Decision: {decision}')\n\n    def process_image(self, image):\n        # Simplified AI processing - in practice, this would use ML models\n        height, width, channels = image.shape\n        if width > height:\n            return \"landscape detected\"\n        else:\n            return \"portrait detected\"\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = AIAgentNode()\n    rclpy.spin(ai_agent)\n    ai_agent.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"4-urdf-fundamentals-for-humanoid-robots",children:"4. URDF Fundamentals for Humanoid Robots"}),"\n",(0,o.jsx)(n.p,{children:"URDF (Unified Robot Description Format) serves as the digital blueprint for humanoid robots, defining their physical structure, joint configurations, and kinematic properties. Think of URDF as the robot's genetic code\u2014it contains all the information needed to understand the robot's physical form and capabilities."}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robots, URDF descriptions become particularly complex due to the intricate structure of human-like bodies. A typical humanoid URDF file defines:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Link elements"})," representing rigid body parts (head, torso, arms, legs)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Joint elements"})," specifying how links connect and move relative to each other"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inertial properties"})," including mass, center of mass, and moment of inertia"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Visual and collision geometry"})," for simulation and planning"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensor mounting points"})," and attachment specifications"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The hierarchical structure of URDF mirrors the kinematic chains found in human anatomy, with the torso serving as the base and limbs extending outward. This structure enables forward and inverse kinematics calculations essential for coordinated movement, allowing the robot to determine how joint angles relate to end-effector positions (like where the hand is located in space)."}),"\n",(0,o.jsx)(n.p,{children:"URDF also integrates with ROS 2's tf (transform) system, which continuously tracks the spatial relationships between all robot parts. This enables sophisticated behaviors like reaching, where the robot must understand the position of its hand relative to its environment and adjust accordingly."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Example: Simplified URDF for a humanoid robot --\x3e\n<?xml version="1.0"?>\n<robot name="simple_humanoid">\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.1 0.1 0.1"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.1 0.1 0.1"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.01" ixy="0.0" ixz="0.0" iyy="0.01" iyz="0.0" izz="0.01"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Head --\x3e\n  <link name="head">\n    <visual>\n      <geometry>\n        <sphere radius="0.05"/>\n      </geometry>\n    </visual>\n  </link>\n\n  <joint name="head_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="head"/>\n    <origin xyz="0 0 0.1"/>\n  </joint>\n\n  \x3c!-- Left Arm --\x3e\n  <link name="left_upper_arm">\n    <visual>\n      <geometry>\n        <cylinder length="0.15" radius="0.02"/>\n      </geometry>\n    </visual>\n  </link>\n\n  <joint name="left_shoulder_joint" type="revolute">\n    <parent link="base_link"/>\n    <child link="left_upper_arm"/>\n    <origin xyz="0.05 0.05 0.05"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="1"/>\n  </joint>\n</robot>\n'})}),"\n",(0,o.jsx)(n.h2,{id:"5-practical-exercise-creating-your-first-ros-2-system",children:"5. Practical Exercise: Creating Your First ROS 2 System"}),"\n",(0,o.jsx)(n.p,{children:"Now let's create a simple ROS 2 system that demonstrates the concepts we've learned. We'll build a system where a sensor node publishes joint positions, and a controller node subscribes to these positions to maintain balance."}),"\n",(0,o.jsx)(n.h3,{id:"exercise-51-joint-position-publisher",children:"Exercise 5.1: Joint Position Publisher"}),"\n",(0,o.jsx)(n.p,{children:"Create a node that simulates joint position sensors for a humanoid robot:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# joint_publisher.py\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nimport math\nimport time\n\nclass JointStatePublisher(Node):\n    def __init__(self):\n        super().__init__('joint_state_publisher')\n        self.publisher_ = self.create_publisher(JointState, 'joint_states', 10)\n\n        # Timer for publishing joint states\n        timer_period = 0.1  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n\n        # Initialize joint positions\n        self.joint_names = ['head_joint', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow']\n        self.joint_positions = [0.0] * len(self.joint_names)\n        self.time_counter = 0.0\n\n    def timer_callback(self):\n        msg = JointState()\n        msg.name = self.joint_names\n        msg.position = self.joint_positions\n\n        # Simulate changing joint positions\n        self.time_counter += 0.1\n        for i in range(len(self.joint_positions)):\n            self.joint_positions[i] = math.sin(self.time_counter + i) * 0.5\n\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.header.frame_id = \"base_link\"\n\n        self.publisher_.publish(msg)\n        self.get_logger().info(f'Publishing joint states: {msg.position}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    joint_publisher = JointStatePublisher()\n    rclpy.spin(joint_publisher)\n    joint_publisher.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h3,{id:"exercise-52-balance-controller",children:"Exercise 5.2: Balance Controller"}),"\n",(0,o.jsx)(n.p,{children:"Create a node that subscribes to joint states and implements a simple balance controller:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# balance_controller.py\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom std_msgs.msg import Float64MultiArray\n\nclass BalanceController(Node):\n    def __init__(self):\n        super().__init__('balance_controller')\n\n        # Subscribe to joint states\n        self.subscription = self.create_subscription(\n            JointState,\n            'joint_states',\n            self.joint_state_callback,\n            10\n        )\n\n        # Publisher for control commands\n        self.command_publisher = self.create_publisher(\n            Float64MultiArray,\n            'balance_commands',\n            10\n        )\n\n        self.get_logger().info('Balance Controller initialized')\n\n    def joint_state_callback(self, msg):\n        # Simple balance control logic\n        # Calculate center of mass based on joint positions\n        total_weight = len(msg.position)\n        if total_weight > 0:\n            avg_position = sum(msg.position) / total_weight\n        else:\n            avg_position = 0.0\n\n        # Generate control commands to maintain balance\n        control_commands = Float64MultiArray()\n        control_commands.data = [avg_position * 0.1]  # Simplified balance correction\n\n        self.command_publisher.publish(control_commands)\n        self.get_logger().info(f'Balance correction: {control_commands.data}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    balance_controller = BalanceController()\n    rclpy.spin(balance_controller)\n    balance_controller.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"6-summary",children:"6. Summary"}),"\n",(0,o.jsx)(n.p,{children:'In this module, you\'ve learned about the fundamental concepts of ROS 2 and its role as the "nervous system" of humanoid robots. You now understand:'}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"How nodes, topics, services, and actions enable distributed robotic systems"}),"\n",(0,o.jsx)(n.li,{children:"How to integrate Python AI agents with robot controllers using rclpy"}),"\n",(0,o.jsx)(n.li,{children:"The importance of URDF in defining humanoid robot structure and capabilities"}),"\n",(0,o.jsx)(n.li,{children:"How to create basic ROS 2 communication patterns for robotic systems"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"These concepts form the foundation for all subsequent modules in this course. The communication patterns you've learned here will be used throughout the course as we build increasingly complex humanoid robot systems."}),"\n",(0,o.jsx)(n.p,{children:"In the next module, we'll explore simulation environments using Gazebo and Unity, where you'll apply these ROS 2 concepts in virtual environments before moving to real hardware."}),"\n",(0,o.jsx)(n.h2,{id:"assessment",children:"Assessment"}),"\n",(0,o.jsx)(n.p,{children:"Complete the following exercises to reinforce your understanding:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Create a ROS 2 node that publishes temperature sensor data and another that subscribes to it to trigger cooling actions"}),"\n",(0,o.jsx)(n.li,{children:"Implement a service that calculates the distance between two points in 3D space"}),"\n",(0,o.jsx)(n.li,{children:"Modify the URDF example to include at least two additional joints for a humanoid leg"}),"\n",(0,o.jsx)(n.li,{children:"Write a Python script using rclpy that integrates a simple machine learning model for object classification"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r});var o=i(6540);const s={},t=o.createContext(s);function r(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}}}]);
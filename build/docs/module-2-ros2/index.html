<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-2-ros2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Module 2 - ROS 2 (Robotic Nervous System) | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://sananaz00.github.io/book_writing_hackathon/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://sananaz00.github.io/book_writing_hackathon/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://sananaz00.github.io/book_writing_hackathon/docs/module-2-ros2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Module 2 - ROS 2 (Robotic Nervous System) | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Understanding ROS 2 architecture and its role in humanoid robotics"><meta data-rh="true" property="og:description" content="Understanding ROS 2 architecture and its role in humanoid robotics"><link data-rh="true" rel="icon" href="/book_writing_hackathon/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://sananaz00.github.io/book_writing_hackathon/docs/module-2-ros2"><link data-rh="true" rel="alternate" href="https://sananaz00.github.io/book_writing_hackathon/docs/module-2-ros2" hreflang="en"><link data-rh="true" rel="alternate" href="https://sananaz00.github.io/book_writing_hackathon/docs/module-2-ros2" hreflang="x-default"><link rel="stylesheet" href="/book_writing_hackathon/assets/css/styles.7785dc77.css">
<script src="/book_writing_hackathon/assets/js/runtime~main.ee4ca24d.js" defer="defer"></script>
<script src="/book_writing_hackathon/assets/js/main.6cf79107.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/book_writing_hackathon/"><div class="navbar__logo"><img src="/book_writing_hackathon/img/logo.svg" alt="Physical AI &amp; Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/book_writing_hackathon/img/logo.svg" alt="Physical AI &amp; Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/book_writing_hackathon/docs/intro">Book</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/SANANAZ00/book_writing_hackathon" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/book_writing_hackathon/docs/intro">Physical AI &amp; Humanoid Robotics</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/book_writing_hackathon/docs/module-2-ros2">Module 2 - ROS 2 (Robotic Nervous System)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/module-3-digital-twin">Module 3 - Digital Twin (Gazebo &amp; Unity)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/module-4-ai-brain">Module 4 - AI-Robot Brain (NVIDIA Isaac)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/module-5-vla">Module 5 - Vision-Language-Action Integration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/module-6-weekly-breakdown">Module 6 - Weekly Breakdown</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/book_writing_hackathon/docs/module-7-capstone">Module 7 - Capstone Project</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><span class="breadcrumbs__link">Physical AI &amp; Humanoid Robotics</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Module 2 - ROS 2 (Robotic Nervous System)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="container container--fluid"><h1 id="module-2-ros-2-robotic-nervous-system">Module 2: ROS 2 (Robotic Nervous System)</h1>
<h2 id="learning-objectives">Learning Objectives</h2>
<p>After completing this module, you will be able to:</p>
<ul>
<li>Explain the core concepts of ROS 2 architecture and its role in humanoid robotics</li>
<li>Implement basic communication patterns using nodes, topics, services, and actions</li>
<li>Integrate Python agents with robot controllers using rclpy</li>
<li>Understand URDF fundamentals specific to humanoid robots</li>
<li>Create and test basic ROS 2 communication systems</li>
</ul>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>Basic Python programming knowledge</li>
<li>Understanding of Linux command line</li>
<li>Completion of Module 1: Introduction</li>
<li>Familiarity with fundamental robotics concepts</li>
</ul>
<h2 id="1-introduction-to-ros-2">1. Introduction to ROS 2</h2>
<p>ROS 2 (Robot Operating System 2) serves as the essential communication backbone that enables complex humanoid robot behaviors. Unlike traditional software systems, ROS 2 provides a distributed computing framework specifically designed for robotics applications, where multiple processes must coordinate seamlessly to achieve complex behaviors.</p>
<p>For humanoid robots specifically, ROS 2 addresses the unique challenge of coordinating dozens of sensors and actuators while maintaining real-time performance. Each componentâ€”vision, motor control, balance, speech recognitionâ€”needs to communicate with every other component, creating a complex web of interactions that ROS 2 manages efficiently.</p>
<h3 id="why-ros-2-for-humanoid-robotics">Why ROS 2 for Humanoid Robotics?</h3>
<p>Humanoid robots require an extraordinary level of coordination between multiple subsystems. From maintaining balance while walking to processing visual input for object recognition, each component must communicate seamlessly with others. ROS 2 provides the infrastructure that allows these diverse systems to function as a unified intelligent agent.</p>
<p>The distributed architecture of ROS 2 is particularly well-suited to humanoid robotics, where different components may run on different processors or even different physical computers within the robot. This flexibility allows for optimal resource allocation while maintaining reliable communication between all system components.</p>
<h2 id="2-core-components-of-ros-2">2. Core Components of ROS 2</h2>
<h3 id="21-nodes-the-processing-units">2.1 Nodes: The Processing Units</h3>
<p>Nodes are the fundamental building blocks of any ROS 2 system. Think of a node as a specialized brain regionâ€”each handles a specific function while remaining connected to the broader network. In a humanoid robot, you might have nodes dedicated to:</p>
<ul>
<li>Motor control for individual joints and limb coordination</li>
<li>Visual processing for cameras and depth sensors</li>
<li>Audio processing for speech recognition and synthesis</li>
<li>Balance and stability algorithms for locomotion</li>
<li>High-level decision making and behavior selection</li>
</ul>
<p>Each node runs independently and communicates with others through ROS 2&#x27;s messaging system, creating a distributed architecture that&#x27;s both flexible and robust.</p>
<pre><code class="language-python"># Example: Simple ROS 2 Node Structure
import rclpy
from rclpy.node import Node

class SimpleRobotNode(Node):
    def __init__(self):
        super().__init__(&#x27;simple_robot_node&#x27;)
        self.get_logger().info(&#x27;Simple Robot Node initialized&#x27;)

def main(args=None):
    rclpy.init(args=args)
    node = SimpleRobotNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h3 id="22-topics-continuous-information-streams">2.2 Topics: Continuous Information Streams</h3>
<p>Topics operate on a publish-subscribe model where one node publishes data and multiple nodes can subscribe to receive it, creating efficient one-to-many communication patterns essential for humanoid robotics. This system is perfect for continuous data streams like sensor readings, camera feeds, or joint position updates.</p>
<p>For example, a camera node continuously publishes image data on a &quot;camera_feed&quot; topic, while multiple perception nodes (face detection, object recognition, depth estimation) can simultaneously subscribe to this stream. Similarly, joint position sensors continuously publish their readings, allowing control algorithms to monitor the robot&#x27;s posture in real-time and make necessary adjustments.</p>
<pre><code class="language-python"># Example: Publisher Node
import rclpy
from rclpy.node import Node
from std_msgs.msg import String

class MinimalPublisher(Node):
    def __init__(self):
        super().__init__(&#x27;minimal_publisher&#x27;)
        self.publisher_ = self.create_publisher(String, &#x27;topic&#x27;, 10)
        timer_period = 0.5  # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0

    def timer_callback(self):
        msg = String()
        msg.data = f&#x27;Hello Robot: {self.i}&#x27;
        self.publisher_.publish(msg)
        self.get_logger().info(f&#x27;Publishing: &quot;{msg.data}&quot;&#x27;)
        self.i += 1

def main(args=None):
    rclpy.init(args=args)
    minimal_publisher = MinimalPublisher()
    rclpy.spin(minimal_publisher)
    minimal_publisher.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<pre><code class="language-python"># Example: Subscriber Node
import rclpy
from rclpy.node import Node
from std_msgs.msg import String

class MinimalSubscriber(Node):
    def __init__(self):
        super().__init__(&#x27;minimal_subscriber&#x27;)
        self.subscription = self.create_subscription(
            String,
            &#x27;topic&#x27;,
            self.listener_callback,
            10)
        self.subscription  # prevent unused variable warning

    def listener_callback(self, msg):
        self.get_logger().info(f&#x27;I heard: &quot;{msg.data}&quot;&#x27;)

def main(args=None):
    rclpy.init(args=args)
    minimal_subscriber = MinimalSubscriber()
    rclpy.spin(minimal_subscriber)
    minimal_subscriber.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h3 id="23-services-request-response-interactions">2.3 Services: Request-Response Interactions</h3>
<p>Services provide synchronous communication for discrete operations that require immediate responses, following a client-server pattern where one node requests an action and waits for completion. This is ideal for operations that must complete before other actions can proceed.</p>
<p>In humanoid robots, services typically handle:</p>
<ul>
<li>Calibration routines that must complete before movement</li>
<li>Database queries for retrieving stored information</li>
<li>Emergency stop procedures that require immediate confirmation</li>
<li>Configuration changes that need validation</li>
</ul>
<pre><code class="language-python"># Example: Service Server
import rclpy
from rclpy.node import Node
from example_interfaces.srv import AddTwoInts

class MinimalService(Node):
    def __init__(self):
        super().__init__(&#x27;minimal_service&#x27;)
        self.srv = self.create_service(AddTwoInts, &#x27;add_two_ints&#x27;, self.add_two_ints_callback)

    def add_two_ints_callback(self, request, response):
        response.sum = request.a + request.b
        self.get_logger().info(f&#x27;Incoming request\na: {request.a}, b: {request.b}\nsum: {response.sum}&#x27;)
        return response

def main(args=None):
    rclpy.init(args=args)
    minimal_service = MinimalService()
    rclpy.spin(minimal_service)
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h3 id="24-actions-long-running-operations-with-feedback">2.4 Actions: Long-Running Operations with Feedback</h3>
<p>Actions bridge the gap between topics and services, handling operations that take time to complete while providing ongoing feedback. They&#x27;re perfect for complex behaviors like walking, grasping, or navigation where progress must be monitored and potentially interrupted.</p>
<p>An action system includes three components: a goal (what to do), feedback (progress updates), and result (final outcome). For a humanoid robot walking to a location, the action would accept the destination goal, continuously provide feedback on walking progress, and return success or failure upon completion.</p>
<h2 id="3-python-agent-integration-with-rclpy">3. Python Agent Integration with rclpy</h2>
<p>rclpy serves as the Python interface to ROS 2, enabling developers to create ROS 2 nodes using familiar Python syntax. This integration is particularly valuable for humanoid robotics because Python excels at rapid prototyping, machine learning integration, and algorithm developmentâ€”critical aspects of physical AI systems.</p>
<p>Through rclpy, Python-based AI agents can seamlessly integrate with the broader ROS 2 ecosystem. A vision-language-action system implemented in Python can subscribe to camera topics, process images using neural networks, and publish commands to motor control nodesâ€”all while leveraging ROS 2&#x27;s robust communication infrastructure.</p>
<p>The Python ecosystem&#x27;s rich libraries for machine learning, computer vision, and natural language processing make rclpy an ideal choice for implementing the cognitive components of humanoid robots. Whether it&#x27;s using TensorFlow for perception tasks or integrating with large language models for natural interaction, rclpy provides the bridge between advanced AI techniques and robotic hardware.</p>
<pre><code class="language-python"># Example: AI Agent Integration with rclpy
import rclpy
from rclpy.node import Node
import numpy as np
from std_msgs.msg import String
from sensor_msgs.msg import Image
import cv2
from cv_bridge import CvBridge

class AIAgentNode(Node):
    def __init__(self):
        super().__init__(&#x27;ai_agent_node&#x27;)

        # Initialize computer vision bridge
        self.bridge = CvBridge()

        # Subscribe to camera feed
        self.image_subscription = self.create_subscription(
            Image,
            &#x27;camera/image_raw&#x27;,
            self.image_callback,
            10
        )

        # Publisher for AI decisions
        self.decision_publisher = self.create_publisher(String, &#x27;ai_decision&#x27;, 10)

        self.get_logger().info(&#x27;AI Agent Node initialized&#x27;)

    def image_callback(self, msg):
        # Convert ROS image message to OpenCV format
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=&#x27;bgr8&#x27;)

        # Process image with AI algorithm (simplified example)
        decision = self.process_image(cv_image)

        # Publish AI decision
        decision_msg = String()
        decision_msg.data = decision
        self.decision_publisher.publish(decision_msg)
        self.get_logger().info(f&#x27;AI Decision: {decision}&#x27;)

    def process_image(self, image):
        # Simplified AI processing - in practice, this would use ML models
        height, width, channels = image.shape
        if width &gt; height:
            return &quot;landscape detected&quot;
        else:
            return &quot;portrait detected&quot;

def main(args=None):
    rclpy.init(args=args)
    ai_agent = AIAgentNode()
    rclpy.spin(ai_agent)
    ai_agent.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h2 id="4-urdf-fundamentals-for-humanoid-robots">4. URDF Fundamentals for Humanoid Robots</h2>
<p>URDF (Unified Robot Description Format) serves as the digital blueprint for humanoid robots, defining their physical structure, joint configurations, and kinematic properties. Think of URDF as the robot&#x27;s genetic codeâ€”it contains all the information needed to understand the robot&#x27;s physical form and capabilities.</p>
<p>For humanoid robots, URDF descriptions become particularly complex due to the intricate structure of human-like bodies. A typical humanoid URDF file defines:</p>
<ul>
<li><strong>Link elements</strong> representing rigid body parts (head, torso, arms, legs)</li>
<li><strong>Joint elements</strong> specifying how links connect and move relative to each other</li>
<li><strong>Inertial properties</strong> including mass, center of mass, and moment of inertia</li>
<li><strong>Visual and collision geometry</strong> for simulation and planning</li>
<li><strong>Sensor mounting points</strong> and attachment specifications</li>
</ul>
<p>The hierarchical structure of URDF mirrors the kinematic chains found in human anatomy, with the torso serving as the base and limbs extending outward. This structure enables forward and inverse kinematics calculations essential for coordinated movement, allowing the robot to determine how joint angles relate to end-effector positions (like where the hand is located in space).</p>
<p>URDF also integrates with ROS 2&#x27;s tf (transform) system, which continuously tracks the spatial relationships between all robot parts. This enables sophisticated behaviors like reaching, where the robot must understand the position of its hand relative to its environment and adjust accordingly.</p>
<pre><code class="language-xml">&lt;!-- Example: Simplified URDF for a humanoid robot --&gt;
&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;robot name=&quot;simple_humanoid&quot;&gt;
  &lt;!-- Base Link --&gt;
  &lt;link name=&quot;base_link&quot;&gt;
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;box size=&quot;0.1 0.1 0.1&quot;/&gt;
      &lt;/geometry&gt;
    &lt;/visual&gt;
    &lt;collision&gt;
      &lt;geometry&gt;
        &lt;box size=&quot;0.1 0.1 0.1&quot;/&gt;
      &lt;/geometry&gt;
    &lt;/collision&gt;
    &lt;inertial&gt;
      &lt;mass value=&quot;1.0&quot;/&gt;
      &lt;inertia ixx=&quot;0.01&quot; ixy=&quot;0.0&quot; ixz=&quot;0.0&quot; iyy=&quot;0.01&quot; iyz=&quot;0.0&quot; izz=&quot;0.01&quot;/&gt;
    &lt;/inertial&gt;
  &lt;/link&gt;

  &lt;!-- Head --&gt;
  &lt;link name=&quot;head&quot;&gt;
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;sphere radius=&quot;0.05&quot;/&gt;
      &lt;/geometry&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint name=&quot;head_joint&quot; type=&quot;fixed&quot;&gt;
    &lt;parent link=&quot;base_link&quot;/&gt;
    &lt;child link=&quot;head&quot;/&gt;
    &lt;origin xyz=&quot;0 0 0.1&quot;/&gt;
  &lt;/joint&gt;

  &lt;!-- Left Arm --&gt;
  &lt;link name=&quot;left_upper_arm&quot;&gt;
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;cylinder length=&quot;0.15&quot; radius=&quot;0.02&quot;/&gt;
      &lt;/geometry&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint name=&quot;left_shoulder_joint&quot; type=&quot;revolute&quot;&gt;
    &lt;parent link=&quot;base_link&quot;/&gt;
    &lt;child link=&quot;left_upper_arm&quot;/&gt;
    &lt;origin xyz=&quot;0.05 0.05 0.05&quot;/&gt;
    &lt;axis xyz=&quot;0 1 0&quot;/&gt;
    &lt;limit lower=&quot;-1.57&quot; upper=&quot;1.57&quot; effort=&quot;100&quot; velocity=&quot;1&quot;/&gt;
  &lt;/joint&gt;
&lt;/robot&gt;
</code></pre>
<h2 id="5-practical-exercise-creating-your-first-ros-2-system">5. Practical Exercise: Creating Your First ROS 2 System</h2>
<p>Now let&#x27;s create a simple ROS 2 system that demonstrates the concepts we&#x27;ve learned. We&#x27;ll build a system where a sensor node publishes joint positions, and a controller node subscribes to these positions to maintain balance.</p>
<h3 id="exercise-51-joint-position-publisher">Exercise 5.1: Joint Position Publisher</h3>
<p>Create a node that simulates joint position sensors for a humanoid robot:</p>
<pre><code class="language-python"># joint_publisher.py
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
import math
import time

class JointStatePublisher(Node):
    def __init__(self):
        super().__init__(&#x27;joint_state_publisher&#x27;)
        self.publisher_ = self.create_publisher(JointState, &#x27;joint_states&#x27;, 10)

        # Timer for publishing joint states
        timer_period = 0.1  # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)

        # Initialize joint positions
        self.joint_names = [&#x27;head_joint&#x27;, &#x27;left_shoulder&#x27;, &#x27;right_shoulder&#x27;, &#x27;left_elbow&#x27;, &#x27;right_elbow&#x27;]
        self.joint_positions = [0.0] * len(self.joint_names)
        self.time_counter = 0.0

    def timer_callback(self):
        msg = JointState()
        msg.name = self.joint_names
        msg.position = self.joint_positions

        # Simulate changing joint positions
        self.time_counter += 0.1
        for i in range(len(self.joint_positions)):
            self.joint_positions[i] = math.sin(self.time_counter + i) * 0.5

        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = &quot;base_link&quot;

        self.publisher_.publish(msg)
        self.get_logger().info(f&#x27;Publishing joint states: {msg.position}&#x27;)

def main(args=None):
    rclpy.init(args=args)
    joint_publisher = JointStatePublisher()
    rclpy.spin(joint_publisher)
    joint_publisher.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h3 id="exercise-52-balance-controller">Exercise 5.2: Balance Controller</h3>
<p>Create a node that subscribes to joint states and implements a simple balance controller:</p>
<pre><code class="language-python"># balance_controller.py
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
from std_msgs.msg import Float64MultiArray

class BalanceController(Node):
    def __init__(self):
        super().__init__(&#x27;balance_controller&#x27;)

        # Subscribe to joint states
        self.subscription = self.create_subscription(
            JointState,
            &#x27;joint_states&#x27;,
            self.joint_state_callback,
            10
        )

        # Publisher for control commands
        self.command_publisher = self.create_publisher(
            Float64MultiArray,
            &#x27;balance_commands&#x27;,
            10
        )

        self.get_logger().info(&#x27;Balance Controller initialized&#x27;)

    def joint_state_callback(self, msg):
        # Simple balance control logic
        # Calculate center of mass based on joint positions
        total_weight = len(msg.position)
        if total_weight &gt; 0:
            avg_position = sum(msg.position) / total_weight
        else:
            avg_position = 0.0

        # Generate control commands to maintain balance
        control_commands = Float64MultiArray()
        control_commands.data = [avg_position * 0.1]  # Simplified balance correction

        self.command_publisher.publish(control_commands)
        self.get_logger().info(f&#x27;Balance correction: {control_commands.data}&#x27;)

def main(args=None):
    rclpy.init(args=args)
    balance_controller = BalanceController()
    rclpy.spin(balance_controller)
    balance_controller.destroy_node()
    rclpy.shutdown()

if __name__ == &#x27;__main__&#x27;:
    main()
</code></pre>
<h2 id="6-summary">6. Summary</h2>
<p>In this module, you&#x27;ve learned about the fundamental concepts of ROS 2 and its role as the &quot;nervous system&quot; of humanoid robots. You now understand:</p>
<ul>
<li>How nodes, topics, services, and actions enable distributed robotic systems</li>
<li>How to integrate Python AI agents with robot controllers using rclpy</li>
<li>The importance of URDF in defining humanoid robot structure and capabilities</li>
<li>How to create basic ROS 2 communication patterns for robotic systems</li>
</ul>
<p>These concepts form the foundation for all subsequent modules in this course. The communication patterns you&#x27;ve learned here will be used throughout the course as we build increasingly complex humanoid robot systems.</p>
<p>In the next module, we&#x27;ll explore simulation environments using Gazebo and Unity, where you&#x27;ll apply these ROS 2 concepts in virtual environments before moving to real hardware.</p>
<h2 id="assessment">Assessment</h2>
<p>Complete the following exercises to reinforce your understanding:</p>
<ol>
<li>Create a ROS 2 node that publishes temperature sensor data and another that subscribes to it to trigger cooling actions</li>
<li>Implement a service that calculates the distance between two points in 3D space</li>
<li>Modify the URDF example to include at least two additional joints for a humanoid leg</li>
<li>Write a Python script using rclpy that integrates a simple machine learning model for object classification</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/book_writing_hackathon/docs/tags/ros-2">ros2</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/book_writing_hackathon/docs/tags/robotics">robotics</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/book_writing_hackathon/docs/tags/middleware">middleware</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/book_writing_hackathon/docs/tags/communication">communication</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/SANANAZ00/book_writing_hackathon/edit/main/docs/module-2-ros2.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/book_writing_hackathon/docs/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/book_writing_hackathon/docs/module-3-digital-twin"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Module 3 - Digital Twin (Gazebo &amp; Unity)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#1-introduction-to-ros-2" class="table-of-contents__link toc-highlight">1. Introduction to ROS 2</a><ul><li><a href="#why-ros-2-for-humanoid-robotics" class="table-of-contents__link toc-highlight">Why ROS 2 for Humanoid Robotics?</a></li></ul></li><li><a href="#2-core-components-of-ros-2" class="table-of-contents__link toc-highlight">2. Core Components of ROS 2</a><ul><li><a href="#21-nodes-the-processing-units" class="table-of-contents__link toc-highlight">2.1 Nodes: The Processing Units</a></li><li><a href="#22-topics-continuous-information-streams" class="table-of-contents__link toc-highlight">2.2 Topics: Continuous Information Streams</a></li><li><a href="#23-services-request-response-interactions" class="table-of-contents__link toc-highlight">2.3 Services: Request-Response Interactions</a></li><li><a href="#24-actions-long-running-operations-with-feedback" class="table-of-contents__link toc-highlight">2.4 Actions: Long-Running Operations with Feedback</a></li></ul></li><li><a href="#3-python-agent-integration-with-rclpy" class="table-of-contents__link toc-highlight">3. Python Agent Integration with rclpy</a></li><li><a href="#4-urdf-fundamentals-for-humanoid-robots" class="table-of-contents__link toc-highlight">4. URDF Fundamentals for Humanoid Robots</a></li><li><a href="#5-practical-exercise-creating-your-first-ros-2-system" class="table-of-contents__link toc-highlight">5. Practical Exercise: Creating Your First ROS 2 System</a><ul><li><a href="#exercise-51-joint-position-publisher" class="table-of-contents__link toc-highlight">Exercise 5.1: Joint Position Publisher</a></li><li><a href="#exercise-52-balance-controller" class="table-of-contents__link toc-highlight">Exercise 5.2: Balance Controller</a></li></ul></li><li><a href="#6-summary" class="table-of-contents__link toc-highlight">6. Summary</a></li><li><a href="#assessment" class="table-of-contents__link toc-highlight">Assessment</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/book_writing_hackathon/docs/intro">Introduction</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/SANANAZ00/book_writing_hackathon" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer><div class="chatbotWidget_q_OK"><button class="chatToggle_zvSz" aria-label="Open chat">ðŸ’¬ AI Assistant</button></div></div>
</body>
</html>